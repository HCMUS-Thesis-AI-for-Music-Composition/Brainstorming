{"cells":[{"cell_type":"markdown","metadata":{"id":"dHKhFQwu1Wbh"},"source":["### Install Library"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-01T07:44:17.127690Z","iopub.status.busy":"2024-07-01T07:44:17.127354Z","iopub.status.idle":"2024-07-01T07:45:17.400493Z","shell.execute_reply":"2024-07-01T07:45:17.399200Z","shell.execute_reply.started":"2024-07-01T07:44:17.127660Z"},"id":"_cJA6hIT1Wbi","trusted":true},"outputs":[],"source":["!pip install miditoolkit -q --use-deprecated=legacy-resolver\n","!pip install transformers[torch] -q --use-deprecated=legacy-resolver\n","!pip install bitsandbytes -q --use-deprecated=legacy-resolver\n","!pip install datasets -q --use-deprecated=legacy-resolver\n","!pip install peft -q --use-deprecated=legacy-resolver\n","!pip install datasets\n","!pip install rouge_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:45:17.403902Z","iopub.status.busy":"2024-07-01T07:45:17.403181Z","iopub.status.idle":"2024-07-01T07:45:17.783993Z","shell.execute_reply":"2024-07-01T07:45:17.782928Z","shell.execute_reply.started":"2024-07-01T07:45:17.403864Z"},"id":"275u_fhs1Wbj","outputId":"cdedc26f-b929-4b45-bd16-7bc7dcec7ac4","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/dataa1/data1.csv\n","/kaggle/input/fullda/full_data.csv\n","/kaggle/input/hihihaha/data1.csv\n"]}],"source":["\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:45:17.797256Z","iopub.status.busy":"2024-07-01T07:45:17.796202Z","iopub.status.idle":"2024-07-01T07:45:17.804400Z","shell.execute_reply":"2024-07-01T07:45:17.803604Z","shell.execute_reply.started":"2024-07-01T07:45:17.797230Z"},"id":"oHVBfFsm1Wbj","trusted":true},"outputs":[],"source":["def load_vocab(vocab_dir):\n","  lines = []\n","  lines = \"\"\n","  with open(vocab_dir, \"r\") as f:\n","    lines = f.readlines()\n","  vocab = []\n","  for ele in lines:\n","    vocab.append(ele.split(\" \")[0])\n","  return vocab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rhGFkz-E1Wbk","trusted":true},"outputs":[],"source":["!pip install gdown\n","!gdown --id 1vIRxkZp8TUz_cMGMuBqBNBcIFg0GsA68"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0FnkGkQu1Wbk","trusted":true},"outputs":[],"source":["!gdown --id 18Ci6oaeoARqpkHadNv6y8_KW9UmW8hlr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PzDNHb1d1Wbk","trusted":true},"outputs":[],"source":["# !unzip /kaggle/working/checkpoint-5988.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:45:17.806164Z","iopub.status.busy":"2024-07-01T07:45:17.805529Z","iopub.status.idle":"2024-07-01T07:45:23.041548Z","shell.execute_reply":"2024-07-01T07:45:23.040644Z","shell.execute_reply.started":"2024-07-01T07:45:17.806131Z"},"id":"zwHCkAre1Wbk","outputId":"8e7d54b9-7ecc-43ab-f74d-3e7079567d79","trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import PreTrainedTokenizerFast\n","tokenizer = PreTrainedTokenizerFast(tokenizer_file=\"/tokenizer101.json\")\n","tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"referenced_widgets":["400030f1c02a4b5db4d98ec81efab21a","ce99940969344346820da4b083d66553","48e258cbc93c4ca996c0c0ab2bdcb86e"]},"execution":{"iopub.execute_input":"2024-07-01T07:45:25.300336Z","iopub.status.busy":"2024-07-01T07:45:25.300044Z","iopub.status.idle":"2024-07-01T07:45:26.062337Z","shell.execute_reply":"2024-07-01T07:45:26.061373Z","shell.execute_reply.started":"2024-07-01T07:45:25.300311Z"},"id":"PYvq9ALe1Wbk","outputId":"3c44b4e9-1b6e-453d-e27f-ae5a9e22fa04","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"400030f1c02a4b5db4d98ec81efab21a","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/85 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce99940969344346820da4b083d66553","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/10 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48e258cbc93c4ca996c0c0ab2bdcb86e","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/6 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["import transformers\n","from datasets import load_dataset, load_metric\n","\n","# Tải dataset từ file CSV\n","medium_datasets = load_dataset(\"csv\", data_files=\"/data.csv\")\n","\n","# Chia dữ liệu thành train, validation và test\n","datasets_train_test = medium_datasets[\"train\"].train_test_split(test_size=0.05)\n","datasets_train_validation = datasets_train_test[\"train\"].train_test_split(test_size=0.1)\n","\n","medium_datasets = {\n","    \"train\": datasets_train_validation[\"train\"],\n","    \"validation\": datasets_train_validation[\"test\"],\n","    \"test\": datasets_train_test[\"test\"]\n","}\n","\n","context_length = 125\n","music_max_length = 1024  \n","\n","# Function for tokenizing the dataset\n","def tokenize_function(examples):\n","    input_ids = []\n","    attention_masks = []\n","    labels = []\n","\n","    for text in examples['0']:\n","        split_data = text.split('<sep>')\n","        if len(split_data) != 2:\n","            continue\n","        prompt = split_data[0].strip()\n","        music = split_data[1].strip()\n","\n","        combined_text = prompt + \" \" + music\n","\n","        tokenized = tokenizer(combined_text, padding=\"max_length\", truncation=True, max_length=context_length + music_max_length)\n","\n","        labels_combined = tokenized['input_ids'].copy()\n","\n","        labels_combined = [-100 if token == tokenizer.pad_token_id else token for token in labels_combined]\n","\n","        input_ids.append(tokenized['input_ids'])\n","        attention_masks.append(tokenized['attention_mask'])\n","        labels.append(labels_combined)\n","\n","    return {\n","        'input_ids': input_ids,\n","        'attention_mask': attention_masks,\n","        'labels': labels\n","    }\n","\n","# Áp dụng hàm tokenize_function cho từng phần dataset\n","tokenized_datasets = {}\n","for split in [\"train\", \"validation\", \"test\"]:\n","    tokenized_datasets[split] = medium_datasets[split].map(\n","        tokenize_function, batched=True, remove_columns=medium_datasets[split].column_names\n","    )\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iLb8pdvq1Wbl","trusted":true},"outputs":[],"source":["medium_datasets[\"train\"][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1yFC2ThZ1Wbl","trusted":true},"outputs":[],"source":["n_layer=20# Number of transformer layers\n","n_head=16 # Number of multi-head attention heads\n","n_emb=1024 # Embedding size\n","\n","from transformers import AutoConfig, GPT2LMHeadModel\n","\n","config = AutoConfig.from_pretrained(\n","    \"gpt2\",\n","    vocab_size=len(tokenizer),\n","    n_positions=2048,\n","    n_layer=n_layer,\n","    n_head=n_head,\n","    pad_token_id=tokenizer.pad_token_id,\n","    bos_token_id=tokenizer.bos_token_id,\n","    eos_token_id=tokenizer.eos_token_id,\n","    n_embd=n_emb)\n","\n","model = GPT2LMHeadModel(config)\n","model.resize_token_embeddings(len(tokenizer))\n","model.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"rbbLTBUE1Wbl"},"source":[","]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hB666BGh1Wbl","trusted":true},"outputs":[],"source":["model.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:47:52.463784Z","iopub.status.busy":"2024-07-01T07:47:52.462925Z","iopub.status.idle":"2024-07-01T07:47:52.482209Z","shell.execute_reply":"2024-07-01T07:47:52.481433Z","shell.execute_reply.started":"2024-07-01T07:47:52.463753Z"},"id":"aziMFBFH1Wbl","outputId":"668e01d1-f894-44d8-e65a-01c5c0cde9b8","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 72,928 || all params: 255,381,728 || trainable%: 0.0286\n"]}],"source":["from peft import LoraConfig\n","\n","# lora_config = LoraConfig( r=16, lora_alpha=32, lora_dropout=0.05, bias=\"none\", task_type= \"CAUSAL_LM\",target_modules=[\"q\", \"v\"] )\n","#target_modules = ['q_proj','k_proj','v_proj','o_proj','gate_proj','down_proj','up_proj','lm_head',\"fc_in\", \"fc_out\", \"wte\"]\n","target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\", \"fc_in\", \"fc_out\", \"wte\", \"lm_head\"]\n","\n","lora_config = LoraConfig(\n","r=16,\n","lora_alpha=12,\n","lora_dropout=0.1,\n","bias=\"none\",\n","target_modules = target_modules,\n","task_type=\"CAUSAL_LM\")\n","from peft import get_peft_model, LoraConfig, TaskType\n","\n","\n","base_model_with_new_adapter = get_peft_model(_model, lora_config)\n","base_model_with_new_adapter.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:47:57.547359Z","iopub.status.busy":"2024-07-01T07:47:57.546479Z","iopub.status.idle":"2024-07-01T07:48:10.862532Z","shell.execute_reply":"2024-07-01T07:48:10.861528Z","shell.execute_reply.started":"2024-07-01T07:47:57.547326Z"},"id":"Ty19r8BE1Wbm","outputId":"62e49fb2-e75e-4b01-d44a-61c8e197de2d","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]}],"source":["\n","from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n","from datasets import load_metric\n","from argparse import Namespace\n","\n","# Define data collator\n","data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)\n","\n","# Configuration parameters\n","config = {\n","    \"output_dir\": \"output_29_6\",\n","    \"num_train_epochs\": 10,\n","    \"fp16\": True,\n","    \"optim\": \"paged_adamw_8bit\",\n","    \"per_device_train_batch_size\": 1,\n","    \"per_device_eval_batch_size\": 1,\n","    \"evaluation_strategy\": \"steps\",\n","    \"save_strategy\": \"steps\",\n","    \"eval_steps\": 500,\n","    \"logging_steps\": 500,\n","    \"logging_first_step\": True,\n","    \"save_total_limit\": 2,\n","    \"save_steps\": 500,\n","    \"lr_scheduler_type\": \"cosine\",\n","    \"learning_rate\": 5e-4,\n","    \"warmup_steps\": 5000,\n","    \"weight_decay\": 0.01,\n","    \"seed\": 1,\n","    \"max_steps\": 50000,\n","    \"gradient_accumulation_steps\": 2\n","}\n","args = Namespace(**config)\n","train_args = TrainingArguments(**config)\n","\n","# Load the ROUGE metric\n","rouge_metric = load_metric(\"rouge\")\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred.predictions, eval_pred.label_ids\n","\n","    # Convert predictions and labels from tensors to lists of integers\n","    predictions = predictions.tolist()\n","    labels = labels.tolist()\n","\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","    decoded_preds = [\"\\n\".join(pred.strip().split()) for pred in decoded_preds]\n","    decoded_labels = [\"\\n\".join(label.strip().split()) for label in decoded_labels]\n","    result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n","    return result\n","\n","# Initialize the Trainer\n","trainer = Trainer(\n","    model=base_model_with_new_adapter,\n","    tokenizer=tokenizer,\n","    args=train_args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],\n","    data_collator=data_collator,\n",")\n","\n","# Train the model\n","#trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rfec_m571Wbm","trusted":true},"outputs":[],"source":["s = \"I1s2_0 I1s2_1_2 I1s2_2_2 I1s2_3_2 I1s2_4_2 I1s2_5_2 I1s2_6_2 I1s2_7_2 I1s2_8_2 I1s2_9_2 I1s2_10_2 I1s2_11_2 I1s2_12_2 I1s2_13_2 I1s2_14_2 I1s2_15_2 I1s2_16_2 I1s2_17_2 I1s2_18_2 I1s2_19_2 I1s2_20_1 I1s2_21_2 I1s2_22_2 I1s2_23_2 I1s2_24_2 I1s2_25_2 I1s2_26_2 I1s2_27_2 I4_28 C1_4 R1_2 R3_3 S2s1_17 S4_0_2 S4_1_2 S4_2_2 S4_3_2 S4_4_2 S4_5_2 S4_6_2 S4_7_2 S4_8_2 S4_9_2 S4_10_2 S4_11_2 S4_12_2 S4_13_2 S4_14_2 S4_15_2 S4_16_2 S4_17_2 S4_18_2 S4_19_2 S4_20_2 S4_21_2 B1s1_4 TS1s1_7 K1_2 T1s1_3 P4_4 ST1_14 EM1_4 TM1_5 <sep> S4_14_2 S4_15_1 S4_16_2 S4_17_1 S4_18_2 S4_19_1 S4_20_1 S4_21_2 B1s1_3 TS1s1_0 K1_2 T1s1_1 P4_3 ST1_14 S4_3_2 S4_4_1 S4_5_1 S4_6_1 S4_7_1 S4_8_1 S4_9_1 S4_10_1 S4_11_1 S4_12_1 S4_13_2 S4_14_1 S4_15_2 S4_16_1 S4_17_1 S4_18_1 S4_19_1 S4_20_2 S4_21_1 B1s1_4 TS1s1_2 K1_2 T1s1_2 P4_5 ST1_14 I1s2_15_0 I1s2_16_1 I1s2_17_2 I1s2_18_1 I1s2_19_2 I1s2_20_2 I1s2_21_2 I1s2_22_1 I1s2_23_2 I1s2_24_1 I1s2_25_1 I1s2_26_2 I1s2_27_1 I4_28 S4_0_2 S4_1_1 S4_2_1 S4_3_1 S4_4_1 S4_5_2 I1s2_8_0\".split(\" \")\n","len(s)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y1Qf2HJG1Wbm","trusted":true},"outputs":[],"source":["output = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:48:10.864638Z","iopub.status.busy":"2024-07-01T07:48:10.864316Z","iopub.status.idle":"2024-07-01T10:44:46.489850Z","shell.execute_reply":"2024-07-01T10:44:46.488762Z","shell.execute_reply.started":"2024-07-01T07:48:10.864606Z"},"id":"xPoyW7qJ1Wbm","outputId":"3ceae7b6-191b-4d8d-ef6c-9ee3476e2393","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.3 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.6"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240701_075001-9kwrzpbd</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/hungprohungzxc123-ahamove/huggingface/runs/9kwrzpbd' target=\"_blank\">crisp-pine-1</a></strong> to <a href='https://wandb.ai/hungprohungzxc123-ahamove/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/hungprohungzxc123-ahamove/huggingface' target=\"_blank\">https://wandb.ai/hungprohungzxc123-ahamove/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/hungprohungzxc123-ahamove/huggingface/runs/9kwrzpbd' target=\"_blank\">https://wandb.ai/hungprohungzxc123-ahamove/huggingface/runs/9kwrzpbd</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='50000' max='50000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [50000/50000 2:54:26, Epoch 1186/1191]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>38000</td>\n","      <td>5.216700</td>\n","      <td>4.683202</td>\n","    </tr>\n","    <tr>\n","      <td>38500</td>\n","      <td>4.246200</td>\n","      <td>4.459696</td>\n","    </tr>\n","    <tr>\n","      <td>39000</td>\n","      <td>3.989200</td>\n","      <td>4.225923</td>\n","    </tr>\n","    <tr>\n","      <td>39500</td>\n","      <td>3.727400</td>\n","      <td>3.950894</td>\n","    </tr>\n","    <tr>\n","      <td>40000</td>\n","      <td>3.436200</td>\n","      <td>3.682172</td>\n","    </tr>\n","    <tr>\n","      <td>40500</td>\n","      <td>3.186500</td>\n","      <td>3.486965</td>\n","    </tr>\n","    <tr>\n","      <td>41000</td>\n","      <td>3.024300</td>\n","      <td>3.362039</td>\n","    </tr>\n","    <tr>\n","      <td>41500</td>\n","      <td>2.908100</td>\n","      <td>3.280823</td>\n","    </tr>\n","    <tr>\n","      <td>42000</td>\n","      <td>2.822800</td>\n","      <td>3.216054</td>\n","    </tr>\n","    <tr>\n","      <td>42500</td>\n","      <td>2.758900</td>\n","      <td>3.173101</td>\n","    </tr>\n","    <tr>\n","      <td>43000</td>\n","      <td>2.714100</td>\n","      <td>3.139947</td>\n","    </tr>\n","    <tr>\n","      <td>43500</td>\n","      <td>2.673400</td>\n","      <td>3.114812</td>\n","    </tr>\n","    <tr>\n","      <td>44000</td>\n","      <td>2.649800</td>\n","      <td>3.102883</td>\n","    </tr>\n","    <tr>\n","      <td>44500</td>\n","      <td>2.626100</td>\n","      <td>3.083807</td>\n","    </tr>\n","    <tr>\n","      <td>45000</td>\n","      <td>2.606800</td>\n","      <td>3.075072</td>\n","    </tr>\n","    <tr>\n","      <td>45500</td>\n","      <td>2.598000</td>\n","      <td>3.067675</td>\n","    </tr>\n","    <tr>\n","      <td>46000</td>\n","      <td>2.589400</td>\n","      <td>3.062002</td>\n","    </tr>\n","    <tr>\n","      <td>46500</td>\n","      <td>2.576400</td>\n","      <td>3.057169</td>\n","    </tr>\n","    <tr>\n","      <td>47000</td>\n","      <td>2.569500</td>\n","      <td>3.053927</td>\n","    </tr>\n","    <tr>\n","      <td>47500</td>\n","      <td>2.566700</td>\n","      <td>3.052503</td>\n","    </tr>\n","    <tr>\n","      <td>48000</td>\n","      <td>2.567100</td>\n","      <td>3.050973</td>\n","    </tr>\n","    <tr>\n","      <td>48500</td>\n","      <td>2.562100</td>\n","      <td>3.050200</td>\n","    </tr>\n","    <tr>\n","      <td>49000</td>\n","      <td>2.557100</td>\n","      <td>3.050005</td>\n","    </tr>\n","    <tr>\n","      <td>49500</td>\n","      <td>2.563800</td>\n","      <td>3.049522</td>\n","    </tr>\n","    <tr>\n","      <td>50000</td>\n","      <td>2.559900</td>\n","      <td>3.049505</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:180: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n","  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"]}],"source":["output = trainer.train(resume_from_checkpoint = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eguY83P51Wbn","trusted":true},"outputs":[],"source":["save_directory = \"/kaggle/working/custom_gpt2_model_28_6\"\n","model.save_pretrained(save_directory)\n","tokenizer.save_pretrained(save_directory)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:46:16.226268Z","iopub.status.busy":"2024-07-01T07:46:16.224983Z","iopub.status.idle":"2024-07-01T07:46:18.107091Z","shell.execute_reply":"2024-07-01T07:46:18.106301Z","shell.execute_reply.started":"2024-07-01T07:46:16.226232Z"},"id":"H3fUf_MS1Wbn","trusted":true},"outputs":[],"source":["from transformers import GPT2LMHeadModel, AutoTokenizer\n","save_directory = \"/kaggle/working/custom_gpt2_model_28_6\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(save_directory)\n","model = GPT2LMHeadModel.from_pretrained(save_directory,    device_map={\"\": \"cpu\"})\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-01T07:46:47.704116Z","iopub.status.busy":"2024-07-01T07:46:47.703143Z","iopub.status.idle":"2024-07-01T07:46:49.477852Z","shell.execute_reply":"2024-07-01T07:46:49.476814Z","shell.execute_reply.started":"2024-07-01T07:46:47.704080Z"},"id":"WADfyvho1Wbn","trusted":true},"outputs":[],"source":["from peft import get_peft_config, PeftModel, PeftConfig, get_peft_model, LoraConfig, TaskType\n","from transformers import GPT2LMHeadModel, AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(save_directory)\n","model = GPT2LMHeadModel.from_pretrained(save_directory,    device_map={\"\": \"cpu\"})\n","\n","_model = PeftModel.from_pretrained(model, \"./output_28_6/checkpoint-45000\", device_map={\"\": \"cpu\"})"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yxyyv0bo1Wbn","trusted":true},"outputs":[],"source":["import torch\n","def generate_music(prompt_text, max_length=512):\n","    input_ids = tokenizer(prompt_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n","\n","    # Generate output\n","    with torch.no_grad():\n","        output_ids = trainer.model.generate(\n","            input_ids,\n","            max_length=max_length,\n","            num_beams=5,\n","            no_repeat_ngram_size=2,\n","            early_stopping=True\n","        )\n","\n","    # Decode output\n","    generated_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n","    return generated_text\n","prompt_text = \"I1s2_0_0 I1s2_1_2 I1s2_2_2 I1s2_3_2 I1s2_4_2 I1s2_5_2 I1s2_6_2 I1s2_7_2 I1s2_8_2 I1s2_9_2 I1s2_10_2 I1s2_11_2 I1s2_12_2 I1s2_13_2 I1s2_14_2 I1s2_15_2 I1s2_16_2 I1s2_17_2 I1s2_18_2 I1s2_19_2 I1s2_20_1 I1s2_21_2 I1s2_22_2 I1s2_23_2 I1s2_24_2 I1s2_25_2 I1s2_26_2 I1s2_27_2 I4_28 C1_4 R1_2 R3_3 S2s1_17 S4_0_2 S4_1_2 S4_2_2 S4_3_2 S4_4_2 S4_5_2 S4_6_2 S4_7_2 S4_8_2 S4_9_2 S4_10_2 S4_11_2 S4_12_2 S4_13_2 S4_14_2 S4_15_2 S4_16_2 S4_17_2 S4_18_2 S4_19_2 S4_20_2 S4_21_2 B1s1_4 TS1s1_7 K1_2 T1s1_3 P4_4 ST1_14 EM1_4 TM1_5 <sep>\"\n","generated_music = generate_music(prompt_text)\n","print(\"Generated Music:\")\n","print(generated_music)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TxHACAcR1Wbn","trusted":true},"outputs":[],"source":["prompt =  \"I1s2_0_0 I1s2_1_2 I1s2_2_2 I1s2_3_2 I1s2_4_2 I1s2_5_2 I1s2_6_2 I1s2_7_2 I1s2_8_2 I1s2_9_2 I1s2_10_2 I1s2_11_2 I1s2_12_2 I1s2_13_2 I1s2_14_2 I1s2_15_2 I1s2_16_2 I1s2_17_2 I1s2_18_2 I1s2_19_2 I1s2_20_1 I1s2_21_2 I1s2_22_2 I1s2_23_2 I1s2_24_2 I1s2_25_2 I1s2_26_2 I1s2_27_2 I4_28 C1_4 R1_2 R3_3 S2s1_17 S4_0_2 S4_1_2 S4_2_2 S4_3_2 S4_4_2 S4_5_2 S4_6_2 S4_7_2 S4_8_2 S4_9_2 S4_10_2 S4_11_2 S4_12_2 S4_13_2 S4_14_2 S4_15_2 S4_16_2 S4_17_2 S4_18_2 S4_19_2 S4_20_2 S4_21_2 B1s1_4 TS1s1_7 K1_2 T1s1_3 P4_4 ST1_14 EM1_4 TM1_5\"\n","#model1 = trainer.model\n","_model = _model.to(\"cuda\")\n","input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").cuda()\n","# Generate more tokens.\n","voice1_generated_ids = _model.generate(\n","    input_ids,\n","    max_length=512,\n","    do_sample=True,\n","    temperature=0.2,\n","    num_beams = 4,\n","    eos_token_id=tokenizer.encode(\"</s>\")[0]\n",")\n","voice2_generated_ids = _model.generate(\n","    input_ids,\n","    max_length=512,\n","    do_sample=True,\n","    temperature=0.2,\n","    eos_token_id=tokenizer.encode(\"</s>\")[0]\n",")\n","voice3_generated_ids = _model.generate(\n","    input_ids,\n","    max_length=512,\n","    do_sample=True,\n","    temperature=0.2,\n","    eos_token_id=tokenizer.encode(\"</s>\")[0]\n",")\n","voice4_generated_ids = _model.generate(\n","    input_ids,\n","    max_length=512,\n","    do_sample=True,\n","    temperature=0.2,\n","    eos_token_id=tokenizer.encode(\"</s>\")[0]\n",")\n","token_sequence = tokenizer.decode(voice4_generated_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YHv2hOAC1Wbn","trusted":true},"outputs":[],"source":["# token_sequence = tokenizer.decode(voice3_generated_ids[0])\n","token_sequence = tokenizer.decode(voice2_generated_ids[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cAHIayKQ1Wbn","trusted":true},"outputs":[],"source":["token_sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MwwbOD2B1Wbn","trusted":true},"outputs":[],"source":["import zipfile\n","import os\n","\n","def zip_folder(folder_path, zip_path):\n","    \"\"\"\n","    Compresses the contents of a folder into a zip file.\n","\n","    :param folder_path: Path to the folder to be compressed.\n","    :param zip_path: Path to the resulting zip file.\n","    \"\"\"\n","    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","        for root, _, files in os.walk(folder_path):\n","            for file in files:\n","                file_path = os.path.join(root, file)\n","                zipf.write(file_path, os.path.relpath(file_path, folder_path))\n","\n","# Example usage:\n","folder_to_zip = \"/kaggle/working/custom_gpt2_model_ver3\"\n","output_zip_file = \"/kaggle/working/custom_gpt2_model_ver3.zip\"\n","\n","zip_folder(folder_to_zip, output_zip_file)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAxm_ulh1Wbo","trusted":true},"outputs":[],"source":["import zipfile\n","import os\n","\n","def zip_folder(folder_path, zip_path):\n","    \"\"\"\n","    Compresses the contents of a folder into a zip file.\n","\n","    :param folder_path: Path to the folder to be compressed.\n","    :param zip_path: Path to the resulting zip file.\n","    \"\"\"\n","    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","        for root, _, files in os.walk(folder_path):\n","            for file in files:\n","                file_path = os.path.join(root, file)\n","                zipf.write(file_path, os.path.relpath(file_path, folder_path))\n","\n","# Example usage:\n","folder_to_zip = \"/kaggle/working/output_9_6\"\n","output_zip_file = \"/kaggle/working/output_9_6.zip\"\n","\n","zip_folder(folder_to_zip, output_zip_file)\n"]}],"metadata":{"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5112500,"sourceId":8554919,"sourceType":"datasetVersion"},{"datasetId":5112613,"sourceId":8555097,"sourceType":"datasetVersion"},{"datasetId":5112624,"sourceId":8555112,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
